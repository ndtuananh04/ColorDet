import cv2
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import os
import random
from sklearn.model_selection import train_test_split
import json

# ======================
# ROI SELECTION & MANAGEMENT
# ======================
class ROIManager:
    def __init__(self, roi_file='roi_config.json'):
        self.roi_file = roi_file
        self.rois = self.load_rois()
        self.current_roi = None
        self.drawing = False
        self.start_point = None
        
    def load_rois(self):
        """Load ROI t·ª´ file JSON"""
        if os.path.exists(self.roi_file):
            with open(self.roi_file, 'r') as f:
                return json.load(f)
        return {}
    
    def save_rois(self):
        """L∆∞u ROI v√†o file JSON"""
        with open(self.roi_file, 'w') as f:
            json.dump(self.rois, f, indent=2)
    
    def mouse_callback(self, event, x, y, flags, param):
        """Callback ƒë·ªÉ v·∫Ω ROI b·∫±ng chu·ªôt"""
        image = param['image']
        window_name = param['window']
        
        if event == cv2.EVENT_LBUTTONDOWN:
            self.drawing = True
            self.start_point = (x, y)
        
        elif event == cv2.EVENT_MOUSEMOVE:
            if self.drawing:
                img_copy = image.copy()
                cv2.rectangle(img_copy, self.start_point, (x, y), (0, 255, 0), 2)
                cv2.imshow(window_name, img_copy)
        
        elif event == cv2.EVENT_LBUTTONUP:
            self.drawing = False
            self.current_roi = (
                min(self.start_point[0], x),
                min(self.start_point[1], y),
                abs(x - self.start_point[0]),
                abs(y - self.start_point[1])
            )
            img_copy = image.copy()
            cv2.rectangle(img_copy, self.start_point, (x, y), (0, 255, 0), 2)
            cv2.imshow(window_name, img_copy)
    
    def select_roi_interactive(self, image, window_name='Select ROI'):
        """Cho ph√©p user v·∫Ω ROI b·∫±ng chu·ªôt"""
        print("\nüìç V·∫Ω ROI b·∫±ng c√°ch k√©o chu·ªôt tr√™n ·∫£nh")
        print("   - Nh·∫•n 'r' ƒë·ªÉ reset")
        print("   - Nh·∫•n 's' ƒë·ªÉ save ROI")
        print("   - Nh·∫•n 'q' ƒë·ªÉ b·ªè qua")
        
        cv2.namedWindow(window_name)
        param = {'image': image, 'window': window_name}
        cv2.setMouseCallback(window_name, self.mouse_callback, param)
        cv2.imshow(window_name, image)
        
        while True:
            key = cv2.waitKey(1) & 0xFF
            
            if key == ord('r'):  # Reset
                self.current_roi = None
                cv2.imshow(window_name, image)
                print("ROI ƒë√£ ƒë∆∞·ª£c reset")
            
            elif key == ord('s'):  # Save
                if self.current_roi is not None:
                    cv2.destroyWindow(window_name)
                    return self.current_roi
                else:
                    print("‚ö†Ô∏è Ch∆∞a v·∫Ω ROI! Vui l√≤ng v·∫Ω tr∆∞·ªõc khi save.")
            
            elif key == ord('q'):  # Quit without saving
                cv2.destroyWindow(window_name)
                return None
        
    def get_roi_for_image(self, image_path, image=None):
        """L·∫•y ROI cho m·ªôt ·∫£nh c·ª• th·ªÉ"""
        # Ki·ªÉm tra xem ƒë√£ c√≥ ROI cho ·∫£nh n√†y ch∆∞a
        if image_path in self.rois:
            roi = self.rois[image_path]
            return tuple(roi)  # (x, y, w, h)
        
        # N·∫øu ch∆∞a c√≥, cho ph√©p user ch·ªçn
        if image is None:
            image = cv2.imread(image_path)
        
        if image is None:
            return None
        
        print(f"\nüñºÔ∏è Ch·ªçn ROI cho: {os.path.basename(image_path)}")
        roi = self.select_roi_interactive(image, f'ROI - {os.path.basename(image_path)}')
        
        if roi is not None:
            self.rois[image_path] = list(roi)
            self.save_rois()
            print(f"‚úÖ ROI ƒë√£ ƒë∆∞·ª£c l∆∞u: {roi}")
        
        return roi
    
    def set_default_roi(self, roi):
        """ƒê·∫∑t ROI m·∫∑c ƒë·ªãnh cho t·∫•t c·∫£ ·∫£nh"""
        self.rois['default'] = list(roi)
        self.save_rois()
    
    def get_default_roi(self):
        """L·∫•y ROI m·∫∑c ƒë·ªãnh"""
        return tuple(self.rois.get('default', None)) if 'default' in self.rois else None

def crop_roi_region(image, roi):
    """Crop ·∫£nh theo ROI ƒë√£ ƒë·ªãnh nghƒ©a"""
    if roi is None:
        return None
    
    x, y, w, h = roi
    # ƒê·∫£m b·∫£o ROI n·∫±m trong ·∫£nh
    x = max(0, x)
    y = max(0, y)
    w = min(w, image.shape[1] - x)
    h = min(h, image.shape[0] - y)
    
    if w <= 0 or h <= 0:
        return None
    
    cropped = image[y:y+h, x:x+w]
    return cropped

# ======================
# DATA AUGMENTATION
# ======================
def augment_image(img):
    """√Åp d·ª•ng random augmentation ƒë·ªÉ tƒÉng c∆∞·ªùng d·ªØ li·ªáu"""
    augmented = img.copy()
    
    # Random blur
    if random.random() > 0.5:
        ksize = random.choice([3, 5])
        augmented = cv2.GaussianBlur(augmented, (ksize, ksize), 0)
    
    # Random brightness
    if random.random() > 0.5:
        factor = random.uniform(0.8, 1.2)
        augmented = np.clip(augmented * factor, 0, 255).astype(np.uint8)
    
    # Random shift (d·ªãch chuy·ªÉn nh·ªè)
    if random.random() > 0.5:
        shift_x = random.randint(-3, 3)
        shift_y = random.randint(-3, 3)
        M = np.float32([[1, 0, shift_x], [0, 1, shift_y]])
        augmented = cv2.warpAffine(augmented, M, (augmented.shape[1], augmented.shape[0]))
    
    # Random rotation (g√≥c nh·ªè)
    if random.random() > 0.5:
        angle = random.uniform(-5, 5)
        h, w = augmented.shape[:2]
        M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1.0)
        augmented = cv2.warpAffine(augmented, M, (w, h))
    
    return augmented

def preprocess_for_1dcnn(cropped, target_length=250, augment=False):
    """Preprocess ·∫£nh ƒë√£ crop th√†nh input cho 1D CNN"""
    if augment:
        cropped = augment_image(cropped)
    
    resized = cv2.resize(cropped, (target_length, 40))
    hsv = cv2.cvtColor(resized, cv2.COLOR_BGR2HSV)
    norm = hsv.astype(np.float32) / 255.0
    avg_line = np.mean(norm, axis=0)
    line_1d = avg_line.T
    return np.expand_dims(line_1d, axis=0)

# ======================
# DATASET
# ======================
class ConnectorDataset(Dataset):
    def __init__(self, image_paths, labels, roi_manager, augment=True, aug_per_image=5):
        """
        image_paths: list c√°c ƒë∆∞·ªùng d·∫´n ·∫£nh
        labels: list c√°c nh√£n (connector type)
        roi_manager: ROIManager instance ƒë·ªÉ l·∫•y ROI
        augment: c√≥ √°p d·ª•ng augmentation kh√¥ng
        aug_per_image: s·ªë l·∫ßn augment m·ªói ·∫£nh
        """
        self.image_paths = image_paths
        self.labels = labels
        self.roi_manager = roi_manager
        self.augment = augment
        self.aug_per_image = aug_per_image
        
        # Load v√† crop t·∫•t c·∫£ ·∫£nh theo ROI
        self.cropped_images = []
        self.valid_indices = []
        
        for idx, img_path in enumerate(image_paths):
            img = cv2.imread(img_path)
            if img is not None:
                # L·∫•y ROI cho ·∫£nh n√†y
                roi = self.roi_manager.get_roi_for_image(img_path, img)
                if roi is None:
                    # Th·ª≠ d√πng ROI m·∫∑c ƒë·ªãnh
                    roi = self.roi_manager.get_default_roi()
                
                if roi is not None:
                    cropped = crop_roi_region(img, roi)
                    if cropped is not None and cropped.size > 0:
                        self.cropped_images.append(cropped)
                        self.valid_indices.append(idx)
        
        print(f"Loaded {len(self.cropped_images)} valid images from {len(image_paths)} total")
        
    def __len__(self):
        if self.augment:
            return len(self.cropped_images) * self.aug_per_image
        return len(self.cropped_images)
    
    def __getitem__(self, idx):
        # T√¨m ·∫£nh g·ªëc t∆∞∆°ng ·ª©ng
        real_idx = idx % len(self.cropped_images)
        cropped = self.cropped_images[real_idx]
        label = self.labels[self.valid_indices[real_idx]]
        
        # Preprocess v·ªõi/kh√¥ng augment
        tensor = preprocess_for_1dcnn(cropped, augment=self.augment)
        tensor = torch.tensor(tensor).float().squeeze(0)  # (3, 250)
        
        return tensor, label

def create_pairs_from_batch(batch_data, batch_labels):
    """T·∫°o c·∫∑p positive v√† negative t·ª´ batch"""
    pairs_1 = []
    pairs_2 = []
    labels = []
    
    batch_size = len(batch_labels)
    
    # T·∫°o positive pairs
    unique_labels = torch.unique(batch_labels)
    for label in unique_labels:
        indices = (batch_labels == label).nonzero(as_tuple=True)[0]
        if len(indices) >= 2:
            # Ch·ªçn ng·∫´u nhi√™n c√°c c·∫∑p c√πng class
            for i in range(len(indices)):
                for j in range(i + 1, len(indices)):
                    pairs_1.append(batch_data[indices[i]])
                    pairs_2.append(batch_data[indices[j]])
                    labels.append(0)  # 0 = same
    
    # T·∫°o negative pairs
    for i in range(batch_size):
        for j in range(i + 1, batch_size):
            if batch_labels[i] != batch_labels[j]:
                pairs_1.append(batch_data[i])
                pairs_2.append(batch_data[j])
                labels.append(1)  # 1 = different
    
    if len(pairs_1) == 0:
        return None, None, None
    
    return torch.stack(pairs_1), torch.stack(pairs_2), torch.tensor(labels).float()

# ======================
# SIAMESE NETWORK
# ======================
class Siamese1DNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv = nn.Sequential(
            nn.Conv1d(3, 32, kernel_size=5, padding=2),
            nn.BatchNorm1d(32),
            nn.ReLU(),
            nn.MaxPool1d(2),
            nn.Dropout(0.2),

            nn.Conv1d(32, 64, kernel_size=5, padding=2),
            nn.BatchNorm1d(64),
            nn.ReLU(),
            nn.MaxPool1d(2),
            nn.Dropout(0.2),

            nn.Conv1d(64, 128, kernel_size=5, padding=2),
            nn.BatchNorm1d(128),
            nn.ReLU(),
            nn.AdaptiveAvgPool1d(8),
            
            nn.Flatten(),
            nn.Linear(128 * 8, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, 128),
        )

    def forward_once(self, x):
        return self.conv(x)

    def forward(self, x1, x2):
        e1 = self.forward_once(x1)
        e2 = self.forward_once(x2)
        return F.pairwise_distance(e1, e2)

# ======================
# CONTRASTIVE LOSS
# ======================
class ContrastiveLoss(nn.Module):
    def __init__(self, margin=1.0):
        super().__init__()
        self.margin = margin
    
    def forward(self, distances, labels):
        # labels: 0 = same, 1 = different
        loss_same = (1 - labels) * torch.pow(distances, 2)
        loss_diff = labels * torch.pow(torch.clamp(self.margin - distances, min=0.0), 2)
        return torch.mean(loss_same + loss_diff)

# ======================
# TRAINING
# ======================
def train_model(train_loader, val_loader, epochs=50, lr=0.001, save_path='siamese_model.pth'):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")
    
    model = Siamese1DNet().to(device)
    criterion = ContrastiveLoss(margin=1.5)
    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)
    
    best_val_loss = float('inf')
    
    for epoch in range(epochs):
        # Training
        model.train()
        train_loss = 0.0
        train_batches = 0
        
        for batch_data, batch_labels in train_loader:
            batch_data = batch_data.to(device)
            batch_labels = batch_labels.to(device)
            
            # T·∫°o pairs t·ª´ batch
            pairs_1, pairs_2, pair_labels = create_pairs_from_batch(batch_data, batch_labels)
            
            if pairs_1 is None:
                continue
            
            pairs_1 = pairs_1.to(device)
            pairs_2 = pairs_2.to(device)
            pair_labels = pair_labels.to(device)
            
            optimizer.zero_grad()
            distances = model(pairs_1, pairs_2)
            loss = criterion(distances, pair_labels)
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            train_batches += 1
        
        avg_train_loss = train_loss / max(train_batches, 1)
        
        # Validation
        model.eval()
        val_loss = 0.0
        val_batches = 0
        
        with torch.no_grad():
            for batch_data, batch_labels in val_loader:
                batch_data = batch_data.to(device)
                batch_labels = batch_labels.to(device)
                
                pairs_1, pairs_2, pair_labels = create_pairs_from_batch(batch_data, batch_labels)
                
                if pairs_1 is None:
                    continue
                
                pairs_1 = pairs_1.to(device)
                pairs_2 = pairs_2.to(device)
                pair_labels = pair_labels.to(device)
                
                distances = model(pairs_1, pairs_2)
                loss = criterion(distances, pair_labels)
                
                val_loss += loss.item()
                val_batches += 1
        
        avg_val_loss = val_loss / max(val_batches, 1)
        scheduler.step(avg_val_loss)
        
        print(f"Epoch [{epoch+1}/{epochs}] - Train Loss: {avg_train_loss:.4f} - Val Loss: {avg_val_loss:.4f}")
        
        # Save best model
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            torch.save(model.state_dict(), save_path)
            print(f"‚úÖ Model saved with val_loss: {avg_val_loss:.4f}")
    
    print(f"\nüéâ Training completed! Best validation loss: {best_val_loss:.4f}")
    return model

# ======================
# ROI SETUP HELPER
# ======================
def setup_rois_for_dataset(data_dir, roi_manager, use_default=True):
    """
    H√†m helper ƒë·ªÉ setup ROI cho to√†n b·ªô dataset
    
    Args:
        data_dir: th∆∞ m·ª•c ch·ª©a data
        roi_manager: ROIManager instance
        use_default: n·∫øu True, ch·ªâ c·∫ßn ch·ªçn ROI m·ªôt l·∫ßn cho t·∫•t c·∫£ ·∫£nh
    """
    if use_default:
        print("\nüéØ Ch·∫ø ƒë·ªô ROI m·∫∑c ƒë·ªãnh: ch·ªçn ROI m·ªôt l·∫ßn cho t·∫•t c·∫£ ·∫£nh")
        
        # L·∫•y ·∫£nh ƒë·∫ßu ti√™n ƒë·ªÉ ch·ªçn ROI
        sample_image_path = None
        for folder_name in os.listdir(data_dir):
            folder_path = os.path.join(data_dir, folder_name)
            if os.path.isdir(folder_path):
                for img_name in os.listdir(folder_path):
                    if img_name.endswith(('.jpg', '.png', '.jpeg')):
                        sample_image_path = os.path.join(folder_path, img_name)
                        break
                if sample_image_path:
                    break
        
        if sample_image_path:
            img = cv2.imread(sample_image_path)
            print(f"\nüì∑ S·ª≠ d·ª•ng ·∫£nh m·∫´u: {os.path.basename(sample_image_path)}")
            roi = roi_manager.select_roi_interactive(img, 'Select Default ROI')
            if roi:
                roi_manager.set_default_roi(roi)
                print(f"‚úÖ ROI m·∫∑c ƒë·ªãnh ƒë√£ ƒë∆∞·ª£c ƒë·∫∑t: {roi}")
                return True
    else:
        print("\nüéØ Ch·∫ø ƒë·ªô ROI ri√™ng bi·ªát: ch·ªçn ROI cho t·ª´ng ·∫£nh")
        print("   (ROI s·∫Ω ƒë∆∞·ª£c ch·ªçn khi load dataset)")
    
    return False

# ======================
# MAIN
# ======================
def main():
    # C·∫•u tr√∫c th∆∞ m·ª•c:
    # data/
    #   ‚îú‚îÄ‚îÄ type1/
    #   ‚îÇ   ‚îú‚îÄ‚îÄ img1.jpg
    #   ‚îÇ   ‚îú‚îÄ‚îÄ img2.jpg
    #   ‚îú‚îÄ‚îÄ type2/
    #   ‚îÇ   ‚îú‚îÄ‚îÄ img1.jpg
    #   ‚îÇ   ‚îú‚îÄ‚îÄ img2.jpg
    
    data_dir = "data"  # Thay ƒë·ªïi ƒë∆∞·ªùng d·∫´n c·ªßa b·∫°n
    
    # Kh·ªüi t·∫°o ROI Manager
    roi_manager = ROIManager(roi_file='roi_config.json')
    
    # Setup ROI (ch·ªçn m·ªôt l·∫ßn cho t·∫•t c·∫£ ho·∫∑c cho t·ª´ng ·∫£nh)
    setup_rois_for_dataset(data_dir, roi_manager, use_default=False)
    
    # Load dataset
    image_paths = []
    labels = []
    
    for label_idx, folder_name in enumerate(sorted(os.listdir(data_dir))):
        folder_path = os.path.join(data_dir, folder_name)
        if os.path.isdir(folder_path):
            for img_name in os.listdir(folder_path):
                if img_name.endswith(('.jpg', '.png', '.jpeg')):
                    image_paths.append(os.path.join(folder_path, img_name))
                    labels.append(label_idx)
    
    print(f"\nüìä Total images: {len(image_paths)}")
    print(f"üìä Number of classes: {len(set(labels))}")
    
    # Split train/val
    train_paths, val_paths, train_labels, val_labels = train_test_split(
        image_paths, labels, test_size=0.2, random_state=42, stratify=labels
    )
    
    # Create datasets v·ªõi augmentation
    train_dataset = ConnectorDataset(train_paths, train_labels, roi_manager, augment=True, aug_per_image=10)
    val_dataset = ConnectorDataset(val_paths, val_labels, roi_manager, augment=False)
    
    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)
    
    # Train
    model = train_model(train_loader, val_loader, epochs=100, lr=0.001)
    
    print("\n‚úÖ Training ho√†n t·∫•t! Model ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o 'siamese_model.pth'")
    print(f"‚úÖ ROI config ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o '{roi_manager.roi_file}'")

if __name__ == "__main__":
    main()